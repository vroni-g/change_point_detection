# ADDITIONAL NEEDED LIBRARIES
library(tidyverse) # for pipe: %>%
library(fields) # for nicer basic plotting: image.plot
install.packages('field')
install.packages('fields')
library(raster)
install.packages('strucchange')
install.packages('changepoint')
# SCRIPT FOR TESTING FUNCTIONS
library("devtools")
load_all()
install.packages('osc')
load_all()
# ADDITIONAL NEEDED LIBRARIES
library(tidyverse) # for pipe: %>%
library(fields) # for nicer basic plotting: image.plot
# GENERAL SETTINGS
str(temp_gistemp)
data=temp_gistemp
# test results for nperm=1000, detrended data
# saveRDS(perm_results, file = "testing/detrended_temp_data_nperm_1000.rds")
perm_results<- readRDS("testing/detrended_temp_data_nperm_1000.rds")
str(perm_results)
View(perm_results)
perm_results$stcs_maxT[!is.finite(perm_results$stcs_maxT)]<- 0
# bootstrap check to check false positive rate
sim_length<- 1000
bootstrap_sample<- 100
fpr_length<- 100
alpha<- 0.05
fpr_sim_stcs<- vector(length = sim_length)
fpr_sim_maxt<- vector(length = sim_length)
fpr_sim_bivariate<- vector(length = sim_length)
for(j in 1:sim_length){
fpr_stcs<- vector(length = fpr_length)
fpr_maxt<- vector(length = fpr_length)
fpr_bivariate<- vector(length = fpr_length)
for (i in 1:fpr_length){
ind<- sample(x = length(perm_results$maxT), size = bootstrap_sample, replace = TRUE)
tmp_stcs<- perm_results$stcs[ind]
tmp_maxt<- perm_results$maxT[ind]
tmp_stcs_maxt<- perm_results$stcs_maxT[ind]
tmp_stcs_maxt[!is.finite(tmp_stcs_maxt)]<- 0
q_thr_stcs<- quantile(tmp_stcs, probs = 1-alpha, names = FALSE)
q_thr_maxt<- quantile(tmp_maxt, probs = 1-alpha, names = FALSE)
q_thr_stcs_maxt<- quantile(tmp_stcs_maxt, probs = 1-alpha, names = FALSE)
fpr_stcs[i]<- tmp_stcs[length(tmp_stcs)] > q_thr_stcs
fpr_maxt[i]<- tmp_maxt[length(tmp_maxt)] > q_thr_maxt
# naive bivariate
fpr_bivariate[i]<- tmp_stcs[length(tmp_stcs)] > quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE) | tmp_stcs_maxt[length(tmp_stcs_maxt)] > quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE)
# slightly too liberal - mean and median =.055
# using bivariate empirical cdf
# library(bivariate)
# biv_distr<- ebvcdf(tmp_stcs, tmp_stcs_maxt)
# fpr_bivariate[i]<- biv_distr(tmp_stcs[length(tmp_stcs)], tmp_stcs_maxt[length(tmp_stcs_maxt)]) > (1-alpha)
# Too conservative
# Using empirical quantile contour line
# contour_line<- get_contour(tmp_stcs, tmp_stcs_maxt, alpha = alpha)
# fpr_bivariate[i]<- (tmp_stcs[length(tmp_stcs)] > max(quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE), max(contour_line$x))) | (tmp_stcs_maxt[length(tmp_stcs_maxt)] > max(quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE), max(contour_line$y)))
}
fpr_sim_stcs[j]<- sum(fpr_stcs)/length(fpr_stcs)
fpr_sim_maxt[j]<- sum(fpr_maxt)/length(fpr_maxt)
fpr_sim_bivariate[j]<- sum(fpr_bivariate)/length(fpr_bivariate)
}
install.packages('bivariate')
library(bivariate)
data=temp_gistemp
# GENERAL SETTINGS
str(temp_gistemp)
fx=sample_mk_function
method="all"
nperm=10
alpha_local=0.05
alpha_global=0.05
null_distribution="normal"
seed=NULL
block_size=NULL
verbose=TRUE
# FOR TESTING LOOP IN perm_dist.R
i=1
# test results for nperm=1000, detrended data
# saveRDS(perm_results, file = "testing/detrended_temp_data_nperm_1000.rds")
perm_results<- readRDS("testing/detrended_temp_data_nperm_1000.rds")
View(perm_results)
str(perm_results)
# GENERAL SETTINGS
str(temp_gistemp)
perm_results$stcs_maxT[!is.finite(perm_results$stcs_maxT)] <- 0
# bootstrap check to check false positive rate
sim_length<- 100
bootstrap_sample<- 100
fpr_length<- 100
alpha<- 0.05
fpr_sim_stcs<- vector(length = sim_length)
fpr_sim_maxt<- vector(length = sim_length)
fpr_sim_bivariate<- vector(length = sim_length)
# bootstrap check to check false positive rate
sim_length<- 10
bootstrap_sample<- 100
fpr_length<- 100
alpha<- 0.05
fpr_sim_stcs<- vector(length = sim_length)
fpr_sim_maxt<- vector(length = sim_length)
fpr_sim_bivariate<- vector(length = sim_length)
for(j in 1:sim_length){
fpr_stcs<- vector(length = fpr_length)
fpr_maxt<- vector(length = fpr_length)
fpr_bivariate<- vector(length = fpr_length)
for (i in 1:fpr_length){
ind<- sample(x = length(perm_results$maxT), size = bootstrap_sample, replace = TRUE)
tmp_stcs<- perm_results$stcs[ind]
tmp_maxt<- perm_results$maxT[ind]
tmp_stcs_maxt<- perm_results$stcs_maxT[ind]
tmp_stcs_maxt[!is.finite(tmp_stcs_maxt)]<- 0
q_thr_stcs<- quantile(tmp_stcs, probs = 1-alpha, names = FALSE)
q_thr_maxt<- quantile(tmp_maxt, probs = 1-alpha, names = FALSE)
q_thr_stcs_maxt<- quantile(tmp_stcs_maxt, probs = 1-alpha, names = FALSE)
fpr_stcs[i]<- tmp_stcs[length(tmp_stcs)] > q_thr_stcs
fpr_maxt[i]<- tmp_maxt[length(tmp_maxt)] > q_thr_maxt
# naive bivariate
fpr_bivariate[i]<- tmp_stcs[length(tmp_stcs)] > quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE) | tmp_stcs_maxt[length(tmp_stcs_maxt)] > quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE)
# slightly too liberal - mean and median =.055
# using bivariate empirical cdf
# library(bivariate)
# biv_distr<- ebvcdf(tmp_stcs, tmp_stcs_maxt)
# fpr_bivariate[i]<- biv_distr(tmp_stcs[length(tmp_stcs)], tmp_stcs_maxt[length(tmp_stcs_maxt)]) > (1-alpha)
# Too conservative
# Using empirical quantile contour line
# contour_line<- get_contour(tmp_stcs, tmp_stcs_maxt, alpha = alpha)
# fpr_bivariate[i]<- (tmp_stcs[length(tmp_stcs)] > max(quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE), max(contour_line$x))) | (tmp_stcs_maxt[length(tmp_stcs_maxt)] > max(quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE), max(contour_line$y)))
}
fpr_sim_stcs[j]<- sum(fpr_stcs)/length(fpr_stcs)
fpr_sim_maxt[j]<- sum(fpr_maxt)/length(fpr_maxt)
fpr_sim_bivariate[j]<- sum(fpr_bivariate)/length(fpr_bivariate)
}
# bootstrap check to check false positive rate
sim_length<- 100
for(j in 1:sim_length){
fpr_stcs<- vector(length = fpr_length)
fpr_maxt<- vector(length = fpr_length)
fpr_bivariate<- vector(length = fpr_length)
for (i in 1:fpr_length){
ind<- sample(x = length(perm_results$maxT), size = bootstrap_sample, replace = TRUE)
tmp_stcs<- perm_results$stcs[ind]
tmp_maxt<- perm_results$maxT[ind]
tmp_stcs_maxt<- perm_results$stcs_maxT[ind]
tmp_stcs_maxt[!is.finite(tmp_stcs_maxt)]<- 0
q_thr_stcs<- quantile(tmp_stcs, probs = 1-alpha, names = FALSE)
q_thr_maxt<- quantile(tmp_maxt, probs = 1-alpha, names = FALSE)
q_thr_stcs_maxt<- quantile(tmp_stcs_maxt, probs = 1-alpha, names = FALSE)
fpr_stcs[i]<- tmp_stcs[length(tmp_stcs)] > q_thr_stcs
fpr_maxt[i]<- tmp_maxt[length(tmp_maxt)] > q_thr_maxt
# naive bivariate
fpr_bivariate[i]<- tmp_stcs[length(tmp_stcs)] > quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE) | tmp_stcs_maxt[length(tmp_stcs_maxt)] > quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE)
# slightly too liberal - mean and median =.055
# using bivariate empirical cdf
# library(bivariate)
# biv_distr<- ebvcdf(tmp_stcs, tmp_stcs_maxt)
# fpr_bivariate[i]<- biv_distr(tmp_stcs[length(tmp_stcs)], tmp_stcs_maxt[length(tmp_stcs_maxt)]) > (1-alpha)
# Too conservative
# Using empirical quantile contour line
# contour_line<- get_contour(tmp_stcs, tmp_stcs_maxt, alpha = alpha)
# fpr_bivariate[i]<- (tmp_stcs[length(tmp_stcs)] > max(quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE), max(contour_line$x))) | (tmp_stcs_maxt[length(tmp_stcs_maxt)] > max(quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE), max(contour_line$y)))
}
fpr_sim_stcs[j]<- sum(fpr_stcs)/length(fpr_stcs)
fpr_sim_maxt[j]<- sum(fpr_maxt)/length(fpr_maxt)
fpr_sim_bivariate[j]<- sum(fpr_bivariate)/length(fpr_bivariate)
}
# bootstrap check to check false positive rate
sim_length<- 1000
for(j in 1:sim_length){
fpr_stcs<- vector(length = fpr_length)
fpr_maxt<- vector(length = fpr_length)
fpr_bivariate<- vector(length = fpr_length)
for (i in 1:fpr_length){
ind<- sample(x = length(perm_results$maxT), size = bootstrap_sample, replace = TRUE)
tmp_stcs<- perm_results$stcs[ind]
tmp_maxt<- perm_results$maxT[ind]
tmp_stcs_maxt<- perm_results$stcs_maxT[ind]
tmp_stcs_maxt[!is.finite(tmp_stcs_maxt)]<- 0
q_thr_stcs<- quantile(tmp_stcs, probs = 1-alpha, names = FALSE)
q_thr_maxt<- quantile(tmp_maxt, probs = 1-alpha, names = FALSE)
q_thr_stcs_maxt<- quantile(tmp_stcs_maxt, probs = 1-alpha, names = FALSE)
fpr_stcs[i]<- tmp_stcs[length(tmp_stcs)] > q_thr_stcs
fpr_maxt[i]<- tmp_maxt[length(tmp_maxt)] > q_thr_maxt
# naive bivariate
fpr_bivariate[i]<- tmp_stcs[length(tmp_stcs)] > quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE) | tmp_stcs_maxt[length(tmp_stcs_maxt)] > quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE)
# slightly too liberal - mean and median =.055
# using bivariate empirical cdf
# library(bivariate)
# biv_distr<- ebvcdf(tmp_stcs, tmp_stcs_maxt)
# fpr_bivariate[i]<- biv_distr(tmp_stcs[length(tmp_stcs)], tmp_stcs_maxt[length(tmp_stcs_maxt)]) > (1-alpha)
# Too conservative
# Using empirical quantile contour line
# contour_line<- get_contour(tmp_stcs, tmp_stcs_maxt, alpha = alpha)
# fpr_bivariate[i]<- (tmp_stcs[length(tmp_stcs)] > max(quantile(tmp_stcs, probs = 1-alpha/2, names = FALSE), max(contour_line$x))) | (tmp_stcs_maxt[length(tmp_stcs_maxt)] > max(quantile(tmp_stcs_maxt, probs = 1-alpha/2, names = FALSE), max(contour_line$y)))
}
fpr_sim_stcs[j]<- sum(fpr_stcs)/length(fpr_stcs)
fpr_sim_maxt[j]<- sum(fpr_maxt)/length(fpr_maxt)
fpr_sim_bivariate[j]<- sum(fpr_bivariate)/length(fpr_bivariate)
}
par(mfrow = c(1, 3))
hist(fpr_sim_stcs)
hist(fpr_sim_maxt)
hist(fpr_sim_bivariate)
par(mfrow = c(1, 1))
summary(fpr_sim_stcs)
summary(fpr_sim_maxt)
summary(fpr_sim_bivariate)
# visualize results for multivariate threshold
# NOTE: outdated df creation
results_df<- do.call(rbind, perm_results$stcs_mvt[[1]]) %>% as.data.frame
View(perm_results)
# visualize results for multivariate threshold
# NOTE: outdated df creation
results_df<- do.call(rbind, perm_results$stcs_maxT[[1]]) %>% as.data.frame
# visualize results for multivariate threshold
# NOTE: outdated df creation
results_df<- do.call(rbind, perm_results$stcs_maxT) %>% as.data.frame
for(i in 2:nperm){
tmp<- do.call(rbind, perm_results$stcs_mvt[[i]]) %>% as.data.frame
tmp$results_length<- lapply(perm_results$stcs_mvt[[i]], function(x) x$results %>% length) %>% do.call(c, .)
tmp$results<- NULL
tmp$id<- i
results_df<- rbind(results_df, tmp)
}
nperm = 1000
for(i in 2:nperm){
tmp<- do.call(rbind, perm_results$stcs_mvt[[i]]) %>% as.data.frame
tmp$results_length<- lapply(perm_results$stcs_mvt[[i]], function(x) x$results %>% length) %>% do.call(c, .)
tmp$results<- NULL
tmp$id<- i
results_df<- rbind(results_df, tmp)
}
View(perm_results)
View(perm_results)
# go through the cluster properties / get_stcs step by step:
data=temp_gistemp
# go through the cluster properties / get_stcs step by step:
data=temp_gistemp
# detrend data ----
#***********************
sen0 <- function(y,x){
zyp.slopediff <- function(i, xx, yy, n) (yy[1:(n - i)] - yy[(i + 1):n])/(xx[1:(n - i)] - xx[(i + 1):n])
n <- length(y)
if (missing(x)) x <- c(1:n)
slopes <- unlist(lapply(1:(n - 1), zyp.slopediff, x, y, n))
return(median(slopes[is.finite(slopes)], na.rm=TRUE))
}
data_detrend<- data %>% apply(1:2, # apply(1:2,...) will apply function to every cell
function(x)
{
(x- 1:length(x)*sen0(x))
}
)
data_detrend<-  aperm(data_detrend, c(2,3,1)) # transpose it to put lat & long in the first dimensions again
# set options ----
#***********************
fx=sample_mk_function
method="all"
nperm=1
alpha_local=0.05
alpha_global=0.05
null_distribution="normal" # defines if threshold based on alpha level is drawn from normal or t distribution
seed=NULL
block_size=NULL
verbose=TRUE
data=data_detrend
# perm_dist ----
#***********************
perm_matrix<- perm_matrix(nobs = dim(data)[3], nperm = nperm, block_size = block_size, seed = seed)
perm_matrix
nperm=2
# perm_dist ----
#***********************
perm_matrix<- perm_matrix(nobs = dim(data)[3], nperm = nperm, block_size = block_size, seed = seed)
perm_matrix
nperm=1
# perm_dist ----
#***********************
perm_matrix<- perm_matrix(nobs = dim(data)[3], nperm = nperm, block_size = block_size, seed = seed)
maxT<- vector(length = nperm)
stcs<- vector(length = nperm)
stcs_maxT<- vector(length = nperm)
tmp<- apply(data[,,perm_matrix[1,]], 1:2, fx)
tmp
str(tmp)
# get_stcs ----
#***********************
data=tmp
if(null_distribution == "normal") thr<- qnorm(1-alpha_local/2)
pixel_sign<- sign(data)
pixel_sign
pixel_significant<- abs(data)>thr
pixel_significant
pixel_result<- pixel_sign*pixel_significant
pixel_result
FALSE * 5
TRUE * 5
# positive
pixel_result_pos<- pixel_result
pixel_result_pos[is.na(pixel_result_pos)]<- -999
clusters_pos<- osc::cca(pixel_result_pos,count.cells = TRUE, s=1, mode = 2, # only values >0 are included in osc:cca
count.max  = length(pixel_sign))
cluster_pos
clusters_pos
nperm=5
data=data_detrend
# perm_dist ----
#***********************
perm_matrix<- perm_matrix(nobs = dim(data)[3], nperm = nperm, block_size = block_size, seed = seed)
maxT<- vector(length = nperm)
stcs<- vector(length = nperm)
stcs_maxT<- vector(length = nperm)
stcs_mvt <- vector(length = nperm)
# get_stcs modified ----
#***********************
get_stcs_mod<- function(data, alpha_local, null_distribution, data_dim){
if(null_distribution == "normal") thr<- qnorm(1-alpha_local/2)
if(null_distribution == "t") thr<- qt(1-alpha_local/2, df = data_dim[3]-2)
pixel_sign<- sign(data)
pixel_significant<- abs(data)>thr
pixel_result<- pixel_sign*pixel_significant
# positive
pixel_result_pos<- pixel_result
pixel_result_pos[is.na(pixel_result_pos)]<- -999
clusters_pos<- osc::cca(pixel_result_pos,count.cells = TRUE, s=1, mode = 2, # only values >0 are included in osc:cca
count.max  = length(pixel_sign))
stcs_pos<- max(clusters_pos$cluster.count)
nclust_pos<- length(clusters_pos$cluster.count)
clusters_sep<- vector(mode = "list", length = 2)
# negative
pixel_result_neg<- pixel_result
pixel_result_neg[pixel_result_neg == -1] = 10 # swap signs so that originally negative values will now be considered in osc:cca
pixel_result_neg[pixel_result_neg == 1] = -10
pixel_result_neg[is.na(pixel_result_neg)] = -999
clusters_neg<- osc::cca(pixel_result_neg,count.cells = TRUE, s=1, mode = 2,
count.max = length(pixel_sign))
stcs_neg<- max(clusters_neg$cluster.count)
# join
clusters_neg$clusters[clusters_neg$clusters > 0]<- clusters_neg$clusters[clusters_neg$clusters > 0] + nclust_pos
clusters_sep[[1]]<- clusters_pos$clusters + clusters_neg$clusters
clusters_sep[[2]]<- c(clusters_pos$cluster.count, clusters_neg$cluster.count)
names(clusters_sep)<- c("clusters", "cluster.count")
stcs<- max(clusters_sep$cluster.count, na.rm = TRUE)
stcs_idx<- which(length(clusters_sep$cluster.count)==stcs)
stcs_cluster_results<- data[clusters_sep$clusters==stcs_idx] # retrieve all cells (by position in matrix?) that belong to the biggest cluster
stcs_maxT<- max(stcs_cluster_results, na.rm = TRUE)
# within cluster properties --- maxT works fine, all others are similar or worse
stcs_mvt<- vector(length = length(clusters_sep$cluster.count), mode = "list")
for (i in 1:length(clusters_sep$cluster.count)){
#stcs_mvt[[i]]<- vector(length = 11, mode = "list")
#print(i)
#get results for cluster i and save for later
cluster_results<- data[clusters_sep$clusters==i]
stcs_mvt[[i]]$results<- cluster_results
# maxT
stcs_mvt[[i]]$maxT<- max(cluster_results, na.rm = TRUE)
# avgT
stcs_mvt[[i]]$meanT<- mean(cluster_results, na.rm = TRUE)
# medianT
stcs_mvt[[i]]$medianT<- median(cluster_results, na.rm = TRUE)
# quantiles: 0.90, 0.95
stcs_mvt[[i]]$q90T<- unname(quantile(cluster_results, probs = 0.90, na.rm = TRUE))
stcs_mvt[[i]]$q95T<- unname(quantile(cluster_results, probs = 0.95, na.rm = TRUE))
# average of top: 3, 5, 10 grid cells
stcs_mvt[[i]]$meanTop3<- mean(head(sort(cluster_results, decreasing = TRUE), n=3), na.rm = TRUE)
stcs_mvt[[i]]$meanTop5<- mean(head(sort(cluster_results, decreasing = TRUE), n=5), na.rm = TRUE)
stcs_mvt[[i]]$meanTop10<- mean(head(sort(cluster_results, decreasing = TRUE), n=10), na.rm = TRUE)
# average of top: 5% 10%
stcs_mvt[[i]]$meanTop5percent<- mean(head(sort(cluster_results, decreasing = TRUE), n=length(cluster_results)*.05), na.rm = TRUE)
stcs_mvt[[i]]$meanTop10percent<- mean(head(sort(cluster_results, decreasing = TRUE), n=length(cluster_results)*.10), na.rm = TRUE)
}
return(list(stcs=stcs, clusters=clusters_sep, stcs_maxT=stcs_maxT, stcs_mvt=stcs_mvt))
}
for(i in 1:nperm){
tmp<- apply(data[,,perm_matrix[i,]], 1:2, fx)
maxT[i]<- max(abs(as.vector(tmp)), na.rm = TRUE)
tmp_stcs<- get_stcs_mod(tmp, alpha_local, null_distribution)
stcs[i]<- tmp_stcs$stcs
stcs_maxT[i]<- tmp_stcs$stcs_maxT
stcs_mvt[i] <- tmp_stcs$stcs_mvt
if(verbose) if((i%%10)==0) cat(i,"\n")
}
warnings()
stcs
stcs_maxT
nperm=20
# perm_dist ----
#***********************
perm_matrix<- perm_matrix(nobs = dim(data)[3], nperm = nperm, block_size = block_size, seed = seed)
data=data_detrend
# perm_dist ----
#***********************
perm_matrix<- perm_matrix(nobs = dim(data)[3], nperm = nperm, block_size = block_size, seed = seed)
maxT<- vector(length = nperm)
stcs<- vector(length = nperm)
stcs_maxT<- vector(length = nperm)
stcs_mvt <- vector(length = nperm)
cat("starting permutations:\n")
for(i in 1:nperm){
tmp<- apply(data[,,perm_matrix[i,]], 1:2, fx)
maxT[i]<- max(abs(as.vector(tmp)), na.rm = TRUE)
tmp_stcs<- get_stcs_mod(tmp, alpha_local, null_distribution)
stcs[i]<- tmp_stcs$stcs
stcs_maxT[i]<- tmp_stcs$stcs_maxT
stcs_mvt[i] <- tmp_stcs$stcs_mvt
if(verbose) if((i%%10)==0) cat(i,"\n")
}
stcs
stcs_mvt
View(stcs_mvt)
tmp<- apply(data[,,perm_matrix[1,]], 1:2, fx)
if(null_distribution == "normal") thr<- qnorm(1-alpha_local/2)
pixel_sign<- sign(data)
pixel_sign
pixel_significant<- abs(data)>thr
pixel_significant
View(stcs_mvt)
pixel_result<- pixel_sign*pixel_significant
# positive
pixel_result_pos<- pixel_result
pixel_result_pos[is.na(pixel_result_pos)]<- -999
clusters_pos<- osc::cca(pixel_result_pos,count.cells = TRUE, s=1, mode = 2, # only values >0 are included in osc:cca
count.max  = length(pixel_sign))
pixel_result<- pixel_sign*pixel_significant
# positive
pixel_result_pos<- pixel_result
pixel_result_pos[is.na(pixel_result_pos)]<- -999
pixel_result_pos
clusters_pos<- osc::cca(pixel_result_pos,count.cells = TRUE, s=1, mode = 2, # only values >0 are included in osc:cca
count.max  = length(pixel_sign))
# get_stcs step by step ----
#***********************
tmp<- apply(data[,,perm_matrix[3,]], 1:2, fx)
data = tmp
if(null_distribution == "normal") thr<- qnorm(1-alpha_local/2)
pixel_sign<- sign(data)
pixel_sign
pixel_significant<- abs(data)>thr
pixel_significant
pixel_result<- pixel_sign*pixel_significant
# positive
pixel_result_pos<- pixel_result
pixel_result_pos[is.na(pixel_result_pos)]<- -999
clusters_pos<- osc::cca(pixel_result_pos,count.cells = TRUE, s=1, mode = 2, # only values >0 are included in osc:cca
count.max  = length(pixel_sign))
View(clusters_pos)
clusters_pos$clusters
clusters_pos$cluster.count
stcs_pos<- max(clusters_pos$cluster.count)
nclust_pos<- length(clusters_pos$cluster.count)
clusters_sep<- vector(mode = "list", length = 2)
# negative
pixel_result_neg<- pixel_result
pixel_result_neg[pixel_result_neg == -1] = 10 # swap signs so that originally negative values will now be considered in osc:cca
pixel_result_neg[pixel_result_neg == 1] = -10
pixel_result_neg[is.na(pixel_result_neg)] = -999
clusters_neg<- osc::cca(pixel_result_neg,count.cells = TRUE, s=1, mode = 2,
count.max = length(pixel_sign))
stcs_neg<- max(clusters_neg$cluster.count)
# join
clusters_neg$clusters[clusters_neg$clusters > 0]<- clusters_neg$clusters[clusters_neg$clusters > 0] + nclust_pos
clusters_sep[[1]]<- clusters_pos$clusters + clusters_neg$clusters
clusters_sep[[2]]<- c(clusters_pos$cluster.count, clusters_neg$cluster.count)
names(clusters_sep)<- c("clusters", "cluster.count")
View(clusters_sep)
clusters_sep$clusters
stcs<- max(clusters_sep$cluster.count, na.rm = TRUE)
stcs_idx<- which(length(clusters_sep$cluster.count)==stcs)
stcs_idx
clusters_sep$cluster.count
stcs_idx<- which(length(clusters_sep$cluster.count)==stcs)
length(clusters_sep$cluster.count)
which(clusters_sep$cluster.count==stcs)
stcs<- max(clusters_sep$cluster.count, na.rm = TRUE)
stcs_idx<- which(clusters_sep$cluster.count==stcs)
stcs_cluster_results<- data[clusters_sep$clusters==stcs_idx] # retrieve all cells (by position in matrix?) that belong to the biggest cluster
stcs_maxT<- max(stcs_cluster_results, na.rm = TRUE)
# within cluster properties --- maxT works fine, all others are similar or worse
stcs_mvt<- vector(length = length(clusters_sep$cluster.count), mode = "list")
View(stcs_mvt)
# within cluster properties --- maxT works fine, all others are similar or worse
stcs_mvt<- vector(length = length(clusters_sep$cluster.count), mode = "list")
rm(stcs_mvt)
# within cluster properties --- maxT works fine, all others are similar or worse
stcs_mvt<- vector(length = length(clusters_sep$cluster.count), mode = "list")
View(stcs_mvt)
for (i in 1:length(clusters_sep$cluster.count)){
#stcs_mvt[[i]]<- vector(length = 11, mode = "list")
#print(i)
#get results for cluster i and save for later
cluster_results<- data[clusters_sep$clusters==i]
stcs_mvt[[i]]$results<- cluster_results
# maxT
stcs_mvt[[i]]$maxT<- max(cluster_results, na.rm = TRUE)
# avgT
stcs_mvt[[i]]$meanT<- mean(cluster_results, na.rm = TRUE)
# medianT
stcs_mvt[[i]]$medianT<- median(cluster_results, na.rm = TRUE)
# quantiles: 0.90, 0.95
stcs_mvt[[i]]$q90T<- unname(quantile(cluster_results, probs = 0.90, na.rm = TRUE))
stcs_mvt[[i]]$q95T<- unname(quantile(cluster_results, probs = 0.95, na.rm = TRUE))
# average of top: 3, 5, 10 grid cells
stcs_mvt[[i]]$meanTop3<- mean(head(sort(cluster_results, decreasing = TRUE), n=3), na.rm = TRUE)
stcs_mvt[[i]]$meanTop5<- mean(head(sort(cluster_results, decreasing = TRUE), n=5), na.rm = TRUE)
stcs_mvt[[i]]$meanTop10<- mean(head(sort(cluster_results, decreasing = TRUE), n=10), na.rm = TRUE)
# average of top: 5% 10%
stcs_mvt[[i]]$meanTop5percent<- mean(head(sort(cluster_results, decreasing = TRUE), n=length(cluster_results)*.05), na.rm = TRUE)
stcs_mvt[[i]]$meanTop10percent<- mean(head(sort(cluster_results, decreasing = TRUE), n=length(cluster_results)*.10), na.rm = TRUE)
}
View(stcs_mvt)
